<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on Data Science Explorer</title>
    <link>/categories/r/</link>
    <description>Recent content in R on Data Science Explorer</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 21 Dec 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/r/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Comparing prediction, human intervention and actual</title>
      <link>/post/comparing-prediction-human-intervention-and-actual/</link>
      <pubDate>Fri, 21 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/comparing-prediction-human-intervention-and-actual/</guid>
      <description>It is common to have machine learning algorithms learn from the variance between actual and predictions but I have seen less examples where human intervention is accounted for as well.
What I am interested in measuring is;
A predicted course of action
 An adjusted course of action, that has been confirmed by a human
 The actual events that occur  Today I am going to create a simple scenario that outlines activity over a single calendar year.</description>
    </item>
    
    <item>
      <title>The games I played in 2018 Part One - EDA</title>
      <link>/post/the-games-i-played-in-2018-part-one-eda/</link>
      <pubDate>Fri, 07 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/the-games-i-played-in-2018-part-one-eda/</guid>
      <description># TODO - add lat and long details of gaming locations # TODO - group games by RPG, digital and board # TODO - add weekday names and weekend/weekday categories # TODO - add morning/afternoon/evening categories  In 2018 I decided to track every game I played using the BG Stats app. The app comes with some built in statistics which are useful but don’t answer all my questions.
Today I’m going to do some exploratory work in R.</description>
    </item>
    
    <item>
      <title>EDA with R and PostgreSQL</title>
      <link>/post/eda-with-r-and-postgresql/</link>
      <pubDate>Mon, 27 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/eda-with-r-and-postgresql/</guid>
      <description>Today I connect my R session to a PostgreSQL database.
I’m using the tutorial database of DVD rentals and this.
My objectives are to;
 learn how to connect R to a database
 practice using SQL queries within R Markdown
 uncover material to use in the SQL project for the Udacity Programming For Data Science Nanodegree  library(tidyverse) library(here) library(ggthemes) library(RPostgreSQL) drv &amp;lt;- dbDriver(&amp;quot;PostgreSQL&amp;quot;) con &amp;lt;- dbConnect(drv, dbname = &amp;quot;dvdrental&amp;quot;, host = &amp;quot;localhost&amp;quot;, port = 5432, user = &amp;quot;postgres&amp;quot;, password = pw) Exploring the database There are 15 tables in this relational database, connected as follows;</description>
    </item>
    
    <item>
      <title>Forecasting AFL Mean Score</title>
      <link>/post/forecasting-afl-mean-score/</link>
      <pubDate>Mon, 09 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/forecasting-afl-mean-score/</guid>
      <description>Today I practice some time-series forecasting techniques in R by applying them to total scores in the AFL.
The question I am interested in answering is - “what kind of average scores should we expect in AFL over next 10 years”
Here are the packages used;
# Packages library(tidyverse) # For everything ## Warning: package &amp;#39;dplyr&amp;#39; was built under R version 3.5.1 library(here) # For project-oriented workflow library(ggthemes) # For nice plot themes library(forecast) # For nice plot themes library(devtools) # For non-CRAN packages library(fitzRoy) # Data source Set up and EDA I create a data set for simple time-series analysis.</description>
    </item>
    
    <item>
      <title>Time Series Forecasting Practice</title>
      <link>/post/time-series-forecasting-practice/</link>
      <pubDate>Tue, 03 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/time-series-forecasting-practice/</guid>
      <description>Today I explore time series forecasting use AFL data from the fitzRoy package.
Key concepts A forecast is the mean of simulated futures.
 Making a ts object
 Trend, Seasonality, Cyclicity
 Plotting lags and ACF
 White noise
 Creating forecast objects
 Checking residuals Mean Absolute Scaled Error Cross Validation Exponential Smoothing   Things to do # TODO - figure out why full ts doesn&amp;#39;t show info from the 1900s # Packages library(tidyverse) # For everything ## Warning: package &amp;#39;dplyr&amp;#39; was built under R version 3.</description>
    </item>
    
    <item>
      <title>One Hour EDA - fitzRoy R Package</title>
      <link>/post/one-hour-eda-fitzroy-r-package/</link>
      <pubDate>Sun, 01 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/one-hour-eda-fitzroy-r-package/</guid>
      <description>Today I take a closer look at the info available in the fitzRoy package.
 This is such a great example of what is happening in the R community these days, the package really takes away the difficulty out of scraping the web for data.
I will limit myself to one hour. This will cover all the poking and prodding of the data and the writing and editing of this post.</description>
    </item>
    
    <item>
      <title>Animated AFL</title>
      <link>/post/animated-afl/</link>
      <pubDate>Thu, 07 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/animated-afl/</guid>
      <description>Today I explore the gganimate package with AFL data from the fitzRoy package.
Here are the packages used.
# Packages library(tidyverse) # For everything library(here) # For project-oriented workflow library(ggthemes) # For nice plot themes library(devtools) # For non-CRAN packages library(fitzRoy) # Data source library(viridis) # Dependancy library(gganimate) # For animation library(animation) # For animation Load results data - easy with the fitzRoy package.
d &amp;lt;- get_match_results() Goal kicking accuracy of home teams I start by looking at goal kicking accuracy for home teams only.</description>
    </item>
    
    <item>
      <title>A bag of barbarian words</title>
      <link>/post/a-bag-of-barbarian-words/</link>
      <pubDate>Mon, 04 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/a-bag-of-barbarian-words/</guid>
      <description>My objective is to learn some text mining techniques and apply them to the very excellent Conan Adventures In An Age Undreamed Of roleplaying game which won best RPG at UK Games Expo 2018. I’m focusing on the Core Book.
I will be loosely following parts of the Text Mining:Bag Of Words course from DataCamp as well as throwing in a few wild tricks of my own and plundering from Stack Overflow, as any barbarian analyst should.</description>
    </item>
    
    <item>
      <title>I don&#39;t want better goal kicking accuracy in the AFL</title>
      <link>/post/i-dont-want-better-goal-kicking-accuracy-in-the-afl/</link>
      <pubDate>Mon, 07 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/i-dont-want-better-goal-kicking-accuracy-in-the-afl/</guid>
      <description>Update: There is far less of a relationship between goal accuracy and margin than originally published - I’ve fixed the error in code below which was using Away.Points instead of Away.Behinds in calculating goal-kicking accuracy.
Today I practice ggplot2 and investigate skills in the AFL.
The #AFLWonkWednesdays week 2 topic is;
What is going on with skills?
There has been a lot of chatter about the quality of skills and goal kicking in the AFL of late.</description>
    </item>
    
    <item>
      <title>2018 Makeover Monday visualisations</title>
      <link>/post/makeover-monday-visualisations/</link>
      <pubDate>Mon, 16 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/makeover-monday-visualisations/</guid>
      <description>I use Makeover Monday to try new visual techniques in R and Tableau.
Week 16 Zambia Southern Province Confirmed Malaria Cases  Week 15 Arctic Sea Ice Tableau version.
 Week 14 Wine Production New techniques used: dplyr::lag to add lag variables and calculate change over time and scale_color_manual for palette
Feedback: Need to add some plain English description of what the chart is showing (the x variable is potentially confusing)</description>
    </item>
    
    <item>
      <title>Learning about kicking in the AFL</title>
      <link>/post/learning-about-kicking-in-the-afl/</link>
      <pubDate>Sun, 15 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/learning-about-kicking-in-the-afl/</guid>
      <description>Today I’m going to have a look at kicking statistics in one of the greatest games on Earth, which is of course Australian Rules Football.
 library(tidyverse) # For everything library(ggthemes) # For some prettier themes Data Big thanks to DFSAustralia for the script that helped me pull this from AFL Tables.
d &amp;lt;- read_csv(&amp;quot;data/afl_stats_2018.csv&amp;quot;) glimpse(d) ## Observations: 1,188 ## Variables: 22 ## $ YR &amp;lt;int&amp;gt; 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 20.</description>
    </item>
    
    <item>
      <title>Basic setup with R</title>
      <link>/post/basic-setup-with-r/</link>
      <pubDate>Mon, 12 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/basic-setup-with-r/</guid>
      <description>This is my basic setup for using R.
If you follow this guide you will be able to collaborate with me easily.
I have kept things as simple as possible, this is more of a checklist than a detailed how-to guide covering every nuance. Here are the steps;
 Install R Install R Studio Create a GitHub account Install GitHub Desktop Set up a project  Install R Go here for Windows.</description>
    </item>
    
  </channel>
</rss>