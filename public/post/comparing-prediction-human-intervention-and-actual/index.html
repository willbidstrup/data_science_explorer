<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <meta name="author" content="Data Science Explorer">
    <meta name="description" content="/">
    <meta name="keywords" content="blog,developer,personal">
    
    <meta property="og:site_name" content="Data Science Explorer">
    <meta property="og:title" content="
  Comparing prediction, human intervention and actual - Data Science Explorer
">
    <meta property="og:description" content="">
    <meta property="og:type" content="website">
    <meta property="og:url" content="/post/comparing-prediction-human-intervention-and-actual/">
    <meta property="og:image" content="/">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="/post/comparing-prediction-human-intervention-and-actual/">
    <meta name="twitter:image" content="/">

    <base href="/">
    <title>
  Comparing prediction, human intervention and actual - Data Science Explorer
</title>

    <link rel="canonical" href="/post/comparing-prediction-human-intervention-and-actual/">
    
    <link  rel="stylesheet" href="https://fonts.googleapis.com/css?family=Fira+Mono:400,700">
    <link rel="stylesheet" href="//cdn.rawgit.com/necolas/normalize.css/master/normalize.css">
    <link rel="stylesheet" href="/css/style.min.css">

    

    

    <link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

    

    <meta name="generator" content="Hugo 0.37.1" />
  </head>

  <body class="">
    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">Data Science Explorer</a>
    <input type="checkbox" id="menu-control"/>
    <label class="menu-mobile  float-right " for="menu-control">
      <span class="btn-mobile  float-right ">&#9776;</span>
      <ul class="navigation-list">
        
          
            <li class="navigation-item  align-center ">
              <a class="navigation-link" href="/post/">Blog</a>
            </li>
          
            <li class="navigation-item  align-center ">
              <a class="navigation-link" href="/projects/">Projects</a>
            </li>
          
            <li class="navigation-item  align-center ">
              <a class="navigation-link" href="/about/">About</a>
            </li>
          
        
        
      </ul>
    </label>
  </section>
</nav>


      <div class="content">
        
  <section class="container page">
  <article>
    <header>
      <h1>Comparing prediction, human intervention and actual</h1>
    </header>

    <p>It is common to have machine learning algorithms learn from the variance between actual and predictions but I have seen less examples where human intervention is accounted for as well.</p>
<p>What I am interested in measuring is;</p>
<ol style="list-style-type: decimal">
<li>A predicted course of action<br />
</li>
<li>An adjusted course of action, that has been confirmed by a human<br />
</li>
<li>The actual events that occur</li>
</ol>
<p>Today I am going to create a simple scenario that outlines activity over a single calendar year. I’m going to use a simplified version of the kind of information I use in Deep Work Supervisor - daily events of ‘deep work’.</p>
<pre class="r"><code>install.packages(&quot;truncnorm&quot;, repos=&quot;http://cran.rstudio.com/&quot;)</code></pre>
<pre><code>## Installing package into &#39;/Users/williambidstrup/Library/R/3.5/library&#39;
## (as &#39;lib&#39; is unspecified)</code></pre>
<pre><code>## 
## The downloaded binary packages are in
##  /var/folders/dj/whwc1h4d2hq8w8qg0dhykkbw0000gn/T//RtmpnjHQHQ/downloaded_packages</code></pre>
<pre class="r"><code>library(here)</code></pre>
<pre><code>## here() starts at /Users/williambidstrup/Documents/GitHub/dse_live</code></pre>
<pre class="r"><code>library(tidyverse)</code></pre>
<pre><code>## ── Attaching packages ─────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ──</code></pre>
<pre><code>## ✔ ggplot2 3.0.0     ✔ purrr   0.2.5
## ✔ tibble  1.4.2     ✔ dplyr   0.7.6
## ✔ tidyr   0.8.1     ✔ stringr 1.3.1
## ✔ readr   1.1.1     ✔ forcats 0.3.0</code></pre>
<pre><code>## ── Conflicts ────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code>library(padr)
library(truncnorm)</code></pre>
<p>First I will create the year with padr.</p>
<pre class="r"><code>dates &lt;- as.Date(c(&quot;2019-01-01&quot;, &quot;2019-01-02&quot;, &quot;2019-12-30&quot;, &quot;2019-12-31&quot;)) 
dates &lt;- as.data.frame(dates)
dates  &lt;- dates %&gt;%
  pad()</code></pre>
<pre><code>## pad applied on the interval: day</code></pre>
<p>I add three activities with a random amount of hours on each day.</p>
<pre class="r"><code>dates$Activity_A &lt;- round(rtruncnorm(n=365, a=0, b=4, mean=4, sd=3))
dates$Activity_B &lt;- round(rtruncnorm(n=365, a=0, b=4, mean=3, sd=1))
dates$Activity_C &lt;- round(rtruncnorm(n=365, a=0, b=4, mean=2, sd=2))</code></pre>
<p>Gather into a single column which will be called the ‘predicted’ scenario. Obviously this is not a prediction, I’m calling it this to refer to the set of inputs that might have come from a prediction</p>
<pre class="r"><code>dates &lt;- dates %&gt;%
  gather(&quot;activity&quot;, &quot;predicted_hours&quot;, 2:4)</code></pre>
<p>Now replicate the steps above to create the ‘human input’ hours and ‘actual’.</p>
<pre class="r"><code>human_input &lt;- as.Date(c(&quot;2019-01-01&quot;, &quot;2019-01-02&quot;, &quot;2019-12-30&quot;, &quot;2019-12-31&quot;)) %&gt;%
  as.data.frame() %&gt;%
  pad()</code></pre>
<pre><code>## pad applied on the interval: day</code></pre>
<pre class="r"><code># Change parameters in rtruncnorm
human_input$Activity_A &lt;- round(rtruncnorm(n=365, a=0, b=4, mean=1, sd=2))
human_input$Activity_B &lt;- round(rtruncnorm(n=365, a=0, b=4, mean=2, sd=1))
human_input$Activity_C &lt;- round(rtruncnorm(n=365, a=0, b=4, mean=3, sd=1))

human_input &lt;- human_input %&gt;%
  gather(&quot;activity&quot;, &quot;human_hours&quot;, 2:4)

names(human_input) &lt;- c(&quot;dates&quot;, &quot;activity&quot;, &quot;human_hours&quot;)</code></pre>
<p>To make the ‘actual’ set I need to make sure future dates are zero. Here I am considering the future to be post June 10th 2019.</p>
<pre class="r"><code>actual_input &lt;- as.Date(c(&quot;2019-01-01&quot;, &quot;2019-01-02&quot;, &quot;2019-12-30&quot;, &quot;2019-12-31&quot;)) %&gt;%
  as.data.frame() %&gt;%
  pad()</code></pre>
<pre><code>## pad applied on the interval: day</code></pre>
<pre class="r"><code># Change parameters in rtruncnorm
actual_input$Activity_A &lt;- round(rtruncnorm(n=365, a=0, b=4, mean=1, sd=2))
actual_input$Activity_B &lt;- round(rtruncnorm(n=365, a=0, b=4, mean=2, sd=1))
actual_input$Activity_C &lt;- round(rtruncnorm(n=365, a=0, b=4, mean=3, sd=1))

actual_input &lt;- actual_input %&gt;%
  gather(&quot;activity&quot;, &quot;actual_hours&quot;, 2:4)

names(actual_input) &lt;- c(&quot;dates&quot;, &quot;activity&quot;, &quot;actual_hours&quot;)

# Filter out half of the year (to simulate full year not yet reached in actual)
actual_input_future &lt;- actual_input %&gt;%
  filter(dates &gt;= &quot;2019-06-10&quot;)

# Make future hours zero
actual_input_future$actual_hours &lt;- 0
rm(future)</code></pre>
<pre><code>## Warning in rm(future): object &#39;future&#39; not found</code></pre>
<pre class="r"><code># Subset actual to past only
actual_input_past &lt;- actual_input[!(actual_input$dates %in% actual_input_future$dates), ]

# Join past and future
actual_input &lt;- actual_input_past %&gt;%
  bind_rows(actual_input_future)</code></pre>
<p>So now I have three identically sized data frames, each representing a number of hours for each of three activities across a whole year. I will combine them into a master data frame which can be used for analysis.</p>
<pre class="r"><code>combined &lt;- dates %&gt;%
  left_join(human_input, by = c(&quot;dates&quot;, &quot;activity&quot;)) %&gt;%
  left_join(actual_input, by = c(&quot;dates&quot;, &quot;activity&quot;))</code></pre>
<p>Which was better? Human or prediction? First tidy the data frame.</p>
<pre class="r"><code>combined_tidy &lt;- combined %&gt;%
  gather(&quot;method&quot;, &quot;hours&quot;, 3:5)</code></pre>
<p>This plot shows a trend line of each method. It’s easy to see the differences.</p>
<pre class="r"><code>ggplot(data = combined_tidy, aes(x = dates, y = hours, col = method, group = method)) +
  geom_smooth(se = FALSE) +
  facet_grid(. ~ activity) +
  theme_minimal() +
  labs(title = &quot;Comparison of prediction, human and actual estimate hours per day per activity&quot;,
       subtitle = &quot;As of June 11th 2019&quot;)</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="/post/2018-12-21-comparing-prediction-human-intervention-and-actual_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>What might be more interesting is measuring the variance between actual and human or predicted.</p>
<pre class="r"><code>combined$human_err &lt;- (abs(combined$human_hours - combined$actual_hours)) / combined$actual_hours
combined$prediction_err &lt;- (abs(combined$predicted_hours - combined$actual_hours)) / combined$actual_hours


combined$winner &lt;- ifelse(combined$human_err &gt; combined$prediction_err, &quot;prediction_better&quot;,
                      ifelse(combined$human_err &lt; combined$prediction_err, &quot;human_better&quot;,
                             ifelse(combined$human_err == combined$prediction_err, &quot;tie&quot;,
                                    ifelse(combined$human_err == Inf | combined$prediction_err == Inf, &quot;infinitely_wrong&quot;, &quot;other&quot;))))

summary(as.factor(combined$winner))</code></pre>
<pre><code>##      human_better prediction_better               tie              NA&#39;s 
##               157               124               734                80</code></pre>
<pre class="r"><code>combined_tidy_error &lt;- combined %&gt;%
  select(&quot;dates&quot;, &quot;activity&quot;, &quot;human_err&quot;, &quot;prediction_err&quot;) %&gt;%
  gather(&quot;method&quot;, &quot;error&quot;, 3:4)</code></pre>
<pre class="r"><code>ggplot(data = combined_tidy_error, aes(x = dates, y = error, col = method)) +
  geom_point(alpha = 0.2) +
  geom_smooth()</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39;</code></pre>
<pre><code>## Warning: Removed 1300 rows containing non-finite values (stat_smooth).</code></pre>
<pre><code>## Warning: Removed 84 rows containing missing values (geom_point).</code></pre>
<p><img src="/post/2018-12-21-comparing-prediction-human-intervention-and-actual_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>

  </article>
</section>


      </div>
      
    </main>

    

  <script src="/js/app.js"></script>
  
  </body>
</html>
