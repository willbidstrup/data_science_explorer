<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <meta name="author" content="Will Bidstrup">
    <meta name="description" content="/">
    <meta name="keywords" content="blog,developer,personal">
    
    <meta property="og:site_name" content="Data Science Explorer">
    <meta property="og:title" content="
  Forecasting AFL Mean Score - Data Science Explorer
">
    <meta property="og:description" content="">
    <meta property="og:type" content="website">
    <meta property="og:url" content="/post/forecasting-afl-mean-score/">
    <meta property="og:image" content="/">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="/post/forecasting-afl-mean-score/">
    <meta name="twitter:image" content="/">

    <base href="/">
    <title>
  Forecasting AFL Mean Score - Data Science Explorer
</title>

    <link rel="canonical" href="/post/forecasting-afl-mean-score/">
    
    <link  rel="stylesheet" href="https://fonts.googleapis.com/css?family=Fira+Mono:400,700">
    <link rel="stylesheet" href="//cdn.rawgit.com/necolas/normalize.css/master/normalize.css">
    <link rel="stylesheet" href="/css/style.min.css">

    

    

    <link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

    

    <meta name="generator" content="Hugo 0.41" />
  </head>

  <body class="">
    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">Data Science Explorer</a>
    <input type="checkbox" id="menu-control"/>
    <label class="menu-mobile  float-right " for="menu-control">
      <span class="btn-mobile  float-right ">&#9776;</span>
      <ul class="navigation-list">
        
          
            <li class="navigation-item  align-center ">
              <a class="navigation-link" href="/post/">Blog</a>
            </li>
          
            <li class="navigation-item  align-center ">
              <a class="navigation-link" href="/tags/">Tags</a>
            </li>
          
            <li class="navigation-item  align-center ">
              <a class="navigation-link" href="/about/">About</a>
            </li>
          
        
        
      </ul>
    </label>
  </section>
</nav>


      <div class="content">
        
  <section class="container page">
  <article>
    <header>
      <h1>Forecasting AFL Mean Score</h1>
    </header>

    <p>Today I practice some time-series forecasting techniques in R by applying them to total scores in the AFL.</p>
<p>The question I am interested in answering is - <em>“what kind of average scores should we expect in AFL over next 10 years”</em></p>
<p>Here are the packages used;</p>
<pre class="r"><code># Packages
library(tidyverse) # For everything</code></pre>
<pre><code>## Warning: package &#39;dplyr&#39; was built under R version 3.5.1</code></pre>
<pre class="r"><code>library(here) # For project-oriented workflow
library(ggthemes) # For nice plot themes
library(forecast) # For nice plot themes
library(devtools) # For non-CRAN packages
library(fitzRoy) # Data source</code></pre>
<div id="set-up-and-eda" class="section level1">
<h1>Set up and EDA</h1>
<p>I create a data set for simple time-series analysis. From fitzRoy package, I have the match results for every game since 1897. I am interested in looking at one metric per year which I will call “Mean Total Score”; this tells us what the average total score in any given year is.</p>
<p>Here is the approach to creating the metric;<br />
- take match results<br />
- convert into a longer format (one game per row)<br />
- summarise by year and calculate mean score for that year</p>
<pre class="r"><code>d &lt;- get_match_results()
d_long &lt;- convert_results(d)

# Create seperate vars for date aspects
d_score &lt;- d_long %&gt;%
  mutate(Date_Full = Date) %&gt;%
  separate(Date, c(&quot;Year&quot;, &quot;Month&quot;, &quot;Day&quot;), sep = &quot;-&quot;)

d_score$score &lt;- as.integer(d_score$Points) 

d_score &lt;- d_score %&gt;%
  group_by(Year) %&gt;%
  summarize(Mean_Total_Score = mean((score), na.rm = TRUE))

# Make ts object
d_score_ts &lt;- ts(d_score[, 2], start = c(1897,1), frequency = 1)</code></pre>
<p>A look at the history shows us a low of 38 pre 1900 before they invented kicking straight, a high of 112 in the glorious early 80’s and a mean for the entire series of 81.</p>
<pre class="r"><code>autoplot(d_score_ts) +
  geom_hline(yintercept = round(mean(d_score$Mean_Total_Score)), linetype = &quot;dashed&quot;) +
  labs(title = &quot;Mean Total Score per year in AFL&quot;,
       subtitle = &quot;Mean for series shown as dashed line (81)&quot;,
       x = &quot;Time&quot;,
       y = &quot;Mean Total Score&quot;)</code></pre>
<p><img src="/post/2018-07-09-forecasting-afl-mean-score_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>A histogram shows that the most commonly occuring Mean Total Score has been between somewhere between 90 and 100 points</p>
<pre class="r"><code>ggplot(data = d_score, aes(x = Mean_Total_Score)) +
  geom_histogram(binwidth = 1) +
    geom_vline(xintercept = round(mean(d_score$Mean_Total_Score)), linetype = &quot;dashed&quot;) +
  coord_flip() +
  labs(title = &quot;Mean Total Score in AFL&quot;,
       subtitle = &quot;Mean for series shown as dashed line&quot;,
       x = &quot;Mean Total Score&quot;,
       y = &quot;Frequency&quot;)</code></pre>
<p><img src="/post/2018-07-09-forecasting-afl-mean-score_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>A boxplot shows a median 85 (shown as thick black line) which sits higher than the mean of 81 (shown as dashed line).</p>
<pre class="r"><code>ggplot(data = d_score, aes(x = &quot;Distribution&quot;, y = Mean_Total_Score)) +
  geom_boxplot() +
  stat_summary(fun.y = mean, geom = &quot;errorbar&quot;, aes(ymax = ..y.., ymin = ..y..),
                 width = .75, linetype = &quot;dashed&quot;) +
  labs(title = &quot;Mean Total Score in AFL&quot;,
       subtitle = &quot;Mean for series shown as dashed line&quot;,
       x = &quot;&quot;,
       y = &quot;Mean Total Score&quot;)</code></pre>
<p><img src="/post/2018-07-09-forecasting-afl-mean-score_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
<div id="model-to-training-set" class="section level1">
<h1>Model to training set</h1>
<p>I think I have enough data to warrant creating a training and test set. I’ll create forecasting models based on the training set from 1897 to 1995 and then apply them to the full data set inclusive of info up until 2018. Each model can then be tested against what really happened and we can see which performs best.</p>
<pre class="r"><code>train &lt;- window(d_score_ts, end = 1995) # Use approx 80% of years as training
test &lt;- window(d_score_ts, start = 1996) </code></pre>
<p>I create four models;<br />
- Naive<br />
- Mean<br />
- SES (Simple Exponential Smoothing)<br />
- ARIMA (Auto Regressive Integrated Moving Average)</p>
<p>I’m using defaults, the point here is to create multiple models so they can be compared against each other. I’m also excluding anlaysis of the residuals of these models, which is also important but not the focus of this exercise. This is an example of a quick look at throwing a few forecasting techniques at a problem before optimizing.</p>
<pre class="r"><code>fit_naive &lt;- naive(train, h = 22)
fit_mean &lt;- meanf(train, h = 22)
fit_ses &lt;- ses(train, h = 22)
fit_arima_train &lt;- auto.arima(train)
fit_arima_train &lt;- forecast(fit_arima_train, h = 22)</code></pre>
</div>
<div id="check-performance-against-test-set-and-measure-accuracy" class="section level1">
<h1>Check performance against test set and measure accuracy</h1>
<p>Now I can plot the forecast results from each modeling method against the test series. Visual inspection can show us that the Naive and SES are probably closest, although none of the models look great.</p>
<pre class="r"><code>autoplot(fit_naive) +
  autolayer(test, series = &quot;Test Series&quot;)</code></pre>
<p><img src="/post/2018-07-09-forecasting-afl-mean-score_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code>autoplot(fit_mean) +
  autolayer(test, series = &quot;Test Series&quot;)</code></pre>
<p><img src="/post/2018-07-09-forecasting-afl-mean-score_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<pre class="r"><code>autoplot(fit_ses) +
  autolayer(test, series = &quot;Test Series&quot;)</code></pre>
<p><img src="/post/2018-07-09-forecasting-afl-mean-score_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<pre class="r"><code>autoplot(fit_arima_train) +
  autolayer(test, series = &quot;Test Series&quot;)</code></pre>
<p><img src="/post/2018-07-09-forecasting-afl-mean-score_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Now that I have the four models, I can compare accuracy by creating a matrix of the results and comparing RMSE against test.</p>
<pre class="r"><code># Create accuracy output for each model
acc_naive &lt;- accuracy(fit_naive, test)
acc_mean &lt;- accuracy(fit_mean, test)
acc_ses &lt;- accuracy(fit_ses, test)
acc_arima &lt;-accuracy(fit_arima_train, test)</code></pre>
<pre class="r"><code># Pull the RMSE value against test set from the accuracy fucntion output
rmse_naive &lt;- acc_naive[[&quot;Test set&quot;, &quot;RMSE&quot;]]
rmse_mean &lt;- acc_mean[[&quot;Test set&quot;, &quot;RMSE&quot;]]
rmse_ses &lt;- acc_ses[[&quot;Test set&quot;, &quot;RMSE&quot;]]
rmse_arima &lt;- acc_arima[[&quot;Test set&quot;, &quot;RMSE&quot;]]</code></pre>
<pre class="r"><code># Create df of the RMSE against test results
models &lt;- c(&quot;Naive&quot;, &quot;Mean&quot;, &quot;SES&quot;, &quot;Arima&quot;)
rmse &lt;- c(rmse_naive, rmse_mean, rmse_ses, rmse_arima)
acc_comp &lt;- data.frame(models, rmse)</code></pre>
<p>Finally I can plot the RMSE of each modelling technique which indeed shows that Naive and SES performed most strongly against the test data.</p>
<pre class="r"><code>ggplot(data = acc_comp, aes(x = reorder(models, -rmse), y = rmse, col = models)) +
  geom_bar(stat = &quot;identity&quot;) +
  labs(title = &quot;RMSE comparison of Mean Total Points forecast models&quot;,
       subtitle = &quot;Trained 1897-1996, Tested 1997-2018&quot;,
       x = &quot;Forecasting method&quot;,
       y = &quot;Root Mean Squared Error&quot;)</code></pre>
<p><img src="/post/2018-07-09-forecasting-afl-mean-score_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
</div>
<div id="apply-best-model-to-future" class="section level1">
<h1>Apply best model to future</h1>
<p>Now I will apply the best perfoming model (naive) and create a forecast ten years into the future. Note the 80 and 95 ranges - it’s very unlikely we will see Mean Total Scores below 60 or a return to the high-scoring 1980s.</p>
<pre class="r"><code>fc_naive &lt;- naive(d_score_ts, h = 10) # h value is number of time periods to forecast

autoplot(fc_naive) +
  autolayer(test, series = &quot;Test Series&quot;) +
  geom_hline(yintercept = round(mean(d_score$Mean_Total_Score)), linetype = &quot;dashed&quot;) +
  labs(title = &quot;Naive forecast method 10 years ahead&quot;,
       subtitle = &quot;Result is close to existing mean (dashed line)&quot;,
       x = &quot;Time&quot;,
       y = &quot;Mean Total Score&quot;)</code></pre>
<p><img src="/post/2018-07-09-forecasting-afl-mean-score_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion</h1>
<p>Against the test set in terms of RMSE, the naive method of forecasting performed most strongly, while the mean method performed the worst.<br />
But, when the naive method is applied to the full set of data that has come before it, it forecasts the Mean Total Score at 82.7 which is very close to the mean of the entire existing data set which is 81.<br />
No technique successfully forecast the downward trend since 2000.<br />
This looks like a good example of regression to the mean although the mean of the set does appear to be rising (78 when calculated 1897-1996 vs 81 for 1897-2018).<br />
This has been a simple look at a straight time-series forecast. In a future post I will incorporate other metrics into the forecasting to see if I can get a better result against the test set (especially forecasting the downward trend).</p>
</div>

  </article>
</section>


      </div>
      
    </main>

    

  <script src="/js/app.js"></script>
  
  </body>
</html>
